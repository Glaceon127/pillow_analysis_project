#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªæ£€æœºåˆ¶æ¨¡å—ï¼šç”¨äºéªŒè¯ Pillow ä¿®å¤è¡Œä¸ºåˆ†æç³»ç»Ÿçš„æ•°æ®å®Œæ•´æ€§ä¸æµç¨‹å¥å£®æ€§ã€‚
è¿è¡Œæ–¹å¼ï¼š
    python self_check.py
æˆ–åœ¨ä¸»æµç¨‹ä¸­è°ƒç”¨ run_all_checks()
"""

import os
import sys
import subprocess
import warnings
import pandas as pd
import ast
from pathlib import Path

# é…ç½®é¡¹ï¼ˆå¯æ ¹æ®ä½ çš„é¡¹ç›®ç»“æ„è°ƒæ•´ï¼‰
CONFIG = {
    "repo_root": ".",                     # Pillow ä»“åº“æ ¹ç›®å½•
    "data_dir": "data",                   # ä¸­é—´æ•°æ®ç›®å½•
    "output_dir": "results",              # æœ€ç»ˆè¾“å‡ºç›®å½•
    "min_fix_commits": 50,                # æœŸæœ›è‡³å°‘æå–åˆ°çš„ä¿®å¤æäº¤æ•°
    "ast_parse_success_threshold": 0.90,  # AST è§£ææˆåŠŸç‡é˜ˆå€¼
    "required_output_files": [
        "aggregated_stats.csv",
        "fix_type_distribution.csv",
        "change_size_by_type.csv"
    ],
    "source_file_list": "data/changed_files.csv"  # è®°å½•æ‰€æœ‰è¢«åˆ†æçš„æºæ–‡ä»¶
}

def log_check(name: str, status: bool, message: str = ""):
    """ç»Ÿä¸€æ—¥å¿—æ ¼å¼"""
    mark = "âœ…" if status else "âŒ"
    print(f"{mark} {name}: {message}")
    return status

def check_git_repo():
    """æ£€æŸ¥å½“å‰ç›®å½•æ˜¯å¦ä¸ºæœ‰æ•ˆçš„ Git ä»“åº“ä¸”æ˜¯ Pillow"""
    try:
        result = subprocess.run(
            ["git", "rev-parse", "--show-toplevel"],
            cwd=CONFIG["repo_root"],
            capture_output=True,
            text=True,
            check=True
        )
        repo_path = result.stdout.strip()
        if not os.path.exists(os.path.join(repo_path, "src/PIL")):
            return log_check("Git ä»“åº“æ£€æŸ¥", False, "æœªæ£€æµ‹åˆ° Pillow æºç ç»“æ„ï¼ˆç¼ºå°‘ src/PILï¼‰")
        return log_check("Git ä»“åº“æ£€æŸ¥", True, f"è·¯å¾„: {repo_path}")
    except (subprocess.CalledProcessError, FileNotFoundError):
        return log_check("Git ä»“åº“æ£€æŸ¥", False, "å½“å‰ç›®å½•ä¸æ˜¯æœ‰æ•ˆçš„ Git ä»“åº“")

def check_extracted_commits():
    """æ£€æŸ¥æ˜¯å¦æˆåŠŸæå–äº†è¶³å¤Ÿæ•°é‡çš„ä¿®å¤æäº¤"""
    commits_file = os.path.join(CONFIG["data_dir"], "fix_commits.csv")
    if not os.path.isfile(commits_file):
        return log_check("ä¿®å¤æäº¤æå–", False, f"æ–‡ä»¶ä¸å­˜åœ¨: {commits_file}")
    
    try:
        df = pd.read_csv(commits_file)
        count = len(df)
        if count < CONFIG["min_fix_commits"]:
            return log_check("ä¿®å¤æäº¤æå–", False, f"ä»…æ‰¾åˆ° {count} ä¸ªä¿®å¤æäº¤ï¼ˆæœŸæœ› â‰¥{CONFIG['min_fix_commits']}ï¼‰")
        return log_check("ä¿®å¤æäº¤æå–", True, f"å…± {count} ä¸ªä¿®å¤æäº¤")
    except Exception as e:
        return log_check("ä¿®å¤æäº¤æå–", False, f"è¯»å–å¤±è´¥: {e}")

def check_ast_parse_success_rate():
    """æ£€æŸ¥ changed_files.csv ä¸­è®°å½•çš„æºæ–‡ä»¶èƒ½å¦è¢« AST æˆåŠŸè§£æ"""
    file_list = CONFIG["source_file_list"]
    if not os.path.isfile(file_list):
        return log_check("AST è§£ææ£€æŸ¥", False, f"æ–‡ä»¶ä¸å­˜åœ¨: {file_list}")

    try:
        df = pd.read_csv(file_list)
        if df.empty:
            return log_check("AST è§£ææ£€æŸ¥", False, "æ— å¾…åˆ†ææ–‡ä»¶")

        total = 0
        success = 0
        failed_files = []

        for _, row in df.iterrows():
            filepath = row.get("file_path")
            if not filepath or not os.path.isfile(filepath):
                continue
            total += 1
            try:
                with open(filepath, "r", encoding="utf-8") as f:
                    source = f.read()
                ast.parse(source)
                success += 1
            except (SyntaxError, UnicodeDecodeError, OSError) as e:
                failed_files.append((filepath, str(e)))

        rate = success / total if total > 0 else 0
        threshold = CONFIG["ast_parse_success_threshold"]

        if rate < threshold:
            msg = f"æˆåŠŸç‡ {rate:.2%} < é˜ˆå€¼ {threshold:.2%}ï¼›å¤±è´¥ç¤ºä¾‹: {failed_files[:2]}"
            return log_check("AST è§£ææ£€æŸ¥", False, msg)
        else:
            return log_check("AST è§£ææ£€æŸ¥", True, f"æˆåŠŸç‡ {rate:.2%} ({success}/{total})")
    except Exception as e:
        return log_check("AST è§£ææ£€æŸ¥", False, f"å¼‚å¸¸: {e}")

def check_fix_type_annotation():
    """æ£€æŸ¥æ¯ä¸ªä¿®å¤æäº¤æ˜¯å¦éƒ½æœ‰éç©ºçš„ fix_type æ ‡ç­¾"""
    stats_file = os.path.join(CONFIG["output_dir"], "fix_type_distribution.csv")
    if not os.path.isfile(stats_file):
        return log_check("ä¿®å¤ç±»å‹æ ‡æ³¨", False, f"æ–‡ä»¶ä¸å­˜åœ¨: {stats_file}")

    try:
        df = pd.read_csv(stats_file)
        if df.empty:
            return log_check("ä¿®å¤ç±»å‹æ ‡æ³¨", False, "åˆ†å¸ƒæ–‡ä»¶ä¸ºç©º")
        
        # å‡è®¾ç¬¬ä¸€åˆ—ä¸ºç±»å‹ï¼Œç¬¬äºŒåˆ—ä¸ºæ•°é‡
        other_ratio = 0.0
        total = df.iloc[:, 1].sum()
        if total == 0:
            return log_check("ä¿®å¤ç±»å‹æ ‡æ³¨", False, "æ€»ä¿®å¤æ•°ä¸º0")

        for _, row in df.iterrows():
            fix_type = str(row.iloc[0]).lower()
            count = row.iloc[1]
            if "other" in fix_type or "unknown" in fix_type:
                other_ratio = count / total
                break

        if other_ratio > 0.7:
            return log_check("ä¿®å¤ç±»å‹æ ‡æ³¨", False, f"'other' ç±»å‹å æ¯”è¿‡é«˜ ({other_ratio:.2%})ï¼Œåˆ†ç±»å¯èƒ½å¤±æ•ˆ")
        return log_check("ä¿®å¤ç±»å‹æ ‡æ³¨", True, f"'other' å æ¯” {other_ratio:.2%}")
    except Exception as e:
        return log_check("ä¿®å¤ç±»å‹æ ‡æ³¨", False, f"è¯»å–å¤±è´¥: {e}")

def check_output_files_exist():
    """æ£€æŸ¥ results/ ç›®å½•æ˜¯å¦åŒ…å«æ‰€æœ‰å¿…éœ€çš„è¾“å‡ºæ–‡ä»¶"""
    missing = []
    for fname in CONFIG["required_output_files"]:
        fpath = os.path.join(CONFIG["output_dir"], fname)
        if not os.path.isfile(fpath):
            missing.append(fname)
    
    if missing:
        return log_check("è¾“å‡ºæ–‡ä»¶å®Œæ•´æ€§", False, f"ç¼ºå¤±æ–‡ä»¶: {missing}")
    else:
        return log_check("è¾“å‡ºæ–‡ä»¶å®Œæ•´æ€§", True, f"å…¨éƒ¨ {len(CONFIG['required_output_files'])} ä¸ªæ–‡ä»¶å­˜åœ¨")

def check_directories():
    """æ£€æŸ¥ data/ å’Œ results/ ç›®å½•æ˜¯å¦å­˜åœ¨"""
    dirs = [CONFIG["data_dir"], CONFIG["output_dir"]]
    missing = [d for d in dirs if not os.path.isdir(d)]
    if missing:
        return log_check("ç›®å½•ç»“æ„", False, f"ç¼ºå¤±ç›®å½•: {missing}")
    return log_check("ç›®å½•ç»“æ„", True, "data/ å’Œ results/ ç›®å½•å­˜åœ¨")

# ==============================
# ä¸»å…¥å£
# ==============================

def run_all_checks():
    """è¿è¡Œæ‰€æœ‰è‡ªæ£€é¡¹"""
    print("ğŸ” æ­£åœ¨è¿è¡Œ Pillow åˆ†æç³»ç»Ÿè‡ªæ£€æœºåˆ¶...\n")
    
    checks = [
        check_directories,
        check_git_repo,
        check_extracted_commits,
        check_ast_parse_success_rate,
        check_fix_type_annotation,
        check_output_files_exist,
    ]

    failed = 0
    for check in checks:
        try:
            result = check()
            if not result:
                failed += 1
        except Exception as e:
            log_check(check.__name__, False, f"å´©æºƒ: {e}")
            failed += 1

    print("\n" + "="*50)
    if failed == 0:
        print("ğŸ‰ æ‰€æœ‰è‡ªæ£€é¡¹é€šè¿‡ï¼ç³»ç»ŸçŠ¶æ€å¥åº·ã€‚")
        return True
    else:
        print(f"âš ï¸  å…± {failed} é¡¹æ£€æŸ¥å¤±è´¥ï¼Œè¯·æ ¹æ®ä¸Šè¿°æç¤ºä¿®å¤ã€‚")
        return False

if __name__ == "__main__":
    success = run_all_checks()
    sys.exit(0 if success else 1)